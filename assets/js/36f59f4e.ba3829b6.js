"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[80487],{92217:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>c});var s=i(74848),t=i(28453);const l={custom_edit_url:"https://github.com/ag2ai/ag2/edit/main/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",source_notebook:"/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",title:"LiteLLM with WatsonX"},o="LiteLLM with WatsonX",a={id:"topics/non-openai-models/cloud-litellm-watsonx",title:"LiteLLM with WatsonX",description:"Open In Colab",source:"@site/docs/topics/non-openai-models/cloud-litellm-watsonx.mdx",sourceDirName:"topics/non-openai-models",slug:"/topics/non-openai-models/cloud-litellm-watsonx",permalink:"/ag2/docs/topics/non-openai-models/cloud-litellm-watsonx",draft:!1,unlisted:!1,editUrl:"https://github.com/ag2ai/ag2/edit/main/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",tags:[],version:"current",frontMatter:{custom_edit_url:"https://github.com/ag2ai/ag2/edit/main/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",source_notebook:"/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",title:"LiteLLM with WatsonX"},sidebar:"docsSidebar",previous:{title:"Groq",permalink:"/ag2/docs/topics/non-openai-models/cloud-groq"},next:{title:"Mistral AI",permalink:"/ag2/docs/topics/non-openai-models/cloud-mistralai"}},r={},c=[{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installing WatsonX",id:"installing-watsonx",level:2},{value:"Installing LiteLLM",id:"installing-litellm",level:2},{value:"Installing AG2",id:"installing-ag2",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.h1,{id:"litellm-with-watsonx",children:"LiteLLM with WatsonX"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.a,{href:"https://colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",children:(0,s.jsx)(e.img,{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,s.jsx)(e.a,{href:"https://github.com/ag2ai/ag2/blob/main/website/docs/topics/non-openai-models/cloud-litellm-watsonx.ipynb",children:(0,s.jsx)(e.img,{src:"https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github",alt:"Open on GitHub"})})]}),"\n",(0,s.jsx)(e.p,{children:"LiteLLM is an open-source, locally run proxy server providing an\nOpenAI-compatible API. It supports various LLM providers, including\nIBM\u2019s WatsonX, enabling seamless integration with tools like AG2."}),"\n",(0,s.jsx)(e.p,{children:"Running LiteLLM with WatsonX requires the following installations:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"AG2"})," \u2013 A framework for building and orchestrating AI agents."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"LiteLLM"})," \u2013 An OpenAI-compatible proxy for bridging non-compliant\nAPIs."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"IBM WatsonX"})," \u2013 LLM service requiring specific session token\nauthentication."]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(e.p,{children:["Before setting up, ensure ",(0,s.jsx)(e.strong,{children:"Docker"})," is installed. Refer to the ",(0,s.jsx)(e.a,{href:"https://docs.docker.com/get-docker/",children:"Docker\ninstallation guide"}),". Optionally,\nconsider using ",(0,s.jsx)(e.strong,{children:"Postman"})," to easily test API requests."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"installing-watsonx",children:"Installing WatsonX"}),"\n",(0,s.jsxs)(e.p,{children:["To set up WatsonX, follow these steps: 1. ",(0,s.jsx)(e.strong,{children:"Access WatsonX:"})," - Sign up\nfor ",(0,s.jsx)(e.a,{href:"https://www.ibm.com/watsonx",children:"WatsonX.ai"}),". - Create an API_KEY and\nPROJECT_ID."]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Validate WatsonX API Access:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Verify access using the following commands:"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Tip: Verify access to watsonX APIs before installing LiteLLM."}),"\n",(0,s.jsx)(e.p,{children:"Get Session Token:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'curl -L "https://iam.cloud.ibm.com/identity/token?=null" \n-H "Content-Type: application/x-www-form-urlencoded" \n-d "grant_type=urn%3Aibm%3Aparams%3Aoauth%3Agrant-type%3Aapikey" \n-d "apikey=<API_KEY>"\n'})}),"\n",(0,s.jsx)(e.p,{children:"Get list of LLMs:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'curl -L "https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2024-09-16&project_id=1eeb4112-5f6e-4a81-9b61-8eac7f9653b4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200" \n-H "Authorization: Bearer <SESSION TOKEN>"\n'})}),"\n",(0,s.jsx)(e.p,{children:"Ask the LLM a question:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'curl -L "https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2023-05-02" \n-H "Content-Type: application/json" \n-H "Accept: application/json" \n-H "Authorization: Bearer <SESSION TOKEN>" \\\n-d "{\n  \\"model_id\\": \\"google/flan-t5-xxl\\",\n  \\"input\\": \\"What is the capital of Arkansas?:\\",\n  \\"parameters\\": {\n    \\"max_new_tokens\\": 100,\n    \\"time_limit\\": 1000\n  },\n  \\"project_id\\": \\"<PROJECT_ID>"}"\n'})}),"\n",(0,s.jsxs)(e.p,{children:["With access to watsonX API\u2019s validated you can install the python\nlibrary from\n",(0,s.jsx)(e.a,{href:"https://ibm.github.io/watsonx-ai-python-sdk/install.html",children:"https://ibm.github.io/watsonx-ai-python-sdk/install.html"})]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"installing-litellm",children:"Installing LiteLLM"}),"\n",(0,s.jsxs)(e.p,{children:["To install LiteLLM, follow these steps: 1. ",(0,s.jsx)(e.strong,{children:"Download LiteLLM Docker\nImage:"})]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"docker pull ghcr.io/berriai/litellm:main-latest\n"})}),"\n",(0,s.jsx)(e.p,{children:"OR"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Install LiteLLM Python Library:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"pip install 'litellm[proxy]'\n"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Create a LiteLLM Configuration File:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:["Save as ",(0,s.jsx)(e.code,{children:"litellm_config.yaml"})," in a local directory."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Example content for WatsonX:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:' model_list:\n    - model_name: llama-3-8b\n    litellm_params:\n       # all params accepted by litellm.completion()\n       model: watsonx/meta-llama/llama-3-8b-instruct\n       api_key: "os.environ/WATSONX_API_KEY" \n       project_id: "os.environ/WX_PROJECT_ID"\n\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'- model_name: "llama_3_2_90"\n   litellm_params:\n      model: watsonx/meta-llama/llama-3-2-90b-vision-instruct\n      api_key: os.environ["WATSONX_APIKEY"] = "" # IBM cloud API key\n      max_new_tokens: 4000\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Start LiteLLM Container:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"docker run -v <Directory>\\litellm_config.yaml:/app/config.yaml -e WATSONX_API_KEY=<API_KEY> -e WATSONX_URL=https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2023-05-02 -e WX_PROJECT_ID=<PROJECT_ID> -p 4000:4000 ghcr.io/berriai/litellm:main-latest --config /app/config.yaml --detailed_debug\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"installing-ag2",children:"Installing AG2"}),"\n",(0,s.jsx)(e.p,{children:"AG2 simplifies orchestration and communication between agents. To\ninstall:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Open a terminal with administrator rights."}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Run the following command:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"pip install ag2\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Once installed, AG2 agents can leverage WatsonX APIs via LiteLLM."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'phi1 = {\n    "config_list": [\n        {\n            "model": "llama-3-8b",\n            "base_url": "http://localhost:4000", #use http://0.0.0.0:4000 for Macs\n            "api_key":"watsonx",\n            "price" : [0,0]\n        },\n    ],\n    "cache_seed": None,  # Disable caching.\n}\n\nphi2 = {\n    "config_list": [\n        {\n            "model": "llama-3-8b",\n            "base_url": "http://localhost:4000", #use http://0.0.0.0:4000 for Macs\n            "api_key":"watsonx",\n            "price" : [0,0]\n        },\n    ],\n    "cache_seed": None,  # Disable caching.\n}\n\nfrom AG2 import ConversableAgent, AssistantAgent\n\njack = ConversableAgent(\n    "Jack (Phi-2)",\n    llm_config=phi2,\n    system_message="Your name is Jack and you are a comedian in a two-person comedy show.",\n)\n\nemma = ConversableAgent(\n    "Emma (Gemma)",\n    llm_config=phi1, \n    system_message="Your name is Emma and you are a comedian in two-person comedy show.",\n)\n\n#AG2\nchat_result = jack.initiate_chat(emma, message="Emma, tell me a joke.", max_turns=2)\n'})})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},28453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>a});var s=i(96540);const t={},l=s.createContext(t);function o(n){const e=s.useContext(l);return s.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);